---
layout: about
title: about
permalink: /
profile:
  align: right
  image: prof_pic.png
  image_circular: false # crops the image to make it circular
notes: true  # includes a list of notes items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page
---

I'm a research engineer at [Ivy](https://lets-unify.ai/), where we endeavor to unify existing ML frameworks such as TensorFlow, PyTorch, Jax, and Numpy. We also work on tools such as a graph compiler to map high-level computational graphs from different frameworks into executable operations on specific devices. Earlier in my career, I was a visiting researcher at the [AdaComp lab](https://adacomp.comp.nus.edu.sg/) in National University of Singapore, working with [Panpan Cai](https://cindycia.github.io/) and [Professor David Hsu](https://www.comp.nus.edu.sg/~dyhsu/) on planning under uncertainty for autonomous vehicles. I hold a master's degree from Oregon State University, where I was advised by [Professor Alan Fern](https://web.engr.oregonstate.edu/~afern/) on explainable and robust reinforcement learning.

Broadly speaking, my research interest lies in reinforcement learning. Over the years, I have delved into several areas within this field, such as explainability in RL, robust and safe RL, and planning and learning under uncertainty. Currently, my focus is on understanding RL algorithms and combining RL and Bayesian Inference.
